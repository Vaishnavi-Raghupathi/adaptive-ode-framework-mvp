# Complete Demo Guide - Week 1 & Week 2

## Quick Start

### Run Week 1 Demo (ODE Solvers)
```bash
cd examples
python week1_demo.py
```

**Output:**
- Console output showing solver fitting and predictions
- Generated plot: `week1_demo.png`
- Topics: Solver comparison, metrics, convergence

**Duration:** ~10-15 seconds

### Run Week 2 Demo (Diagnostics)
```bash
cd examples
python week2_demo.py
```

**Output:**
- Console output with 8-step diagnostic pipeline
- Generated plot: `week2_diagnostics.png`
- Topics: Statistical tests, failure detection, recommendations

**Duration:** ~0.5 seconds

---

## Demo Comparison

| Aspect | Week 1 | Week 2 |
|--------|--------|--------|
| **Focus** | Solving ODEs | Validating Solutions |
| **Input** | Test problem + solver type | Residuals + time points |
| **Process** | Fit â†’ Predict â†’ Evaluate | Analyze â†’ Test â†’ Report |
| **Output** | Solution plots + metrics | Diagnostic plots + recommendations |
| **Tests** | RMSE, RÂ², convergence | Statistical tests (4 types) |
| **Duration** | 10-15 seconds | <1 second |
| **Use Case** | Choose best solver | Improve solver quality |

---

## Week 1 Demo: `examples/week1_demo.py`

### What It Shows

1. **Generate synthetic data** (exponential decay)
2. **Fit solvers** (RK4, RK45)
3. **Compare performance** (RMSE, RÂ², etc.)
4. **Visualize solutions** (exact vs. predicted)

### Key Output

```
[STEP 1] Generate analytical exponential decay data...
  âœ“ Generated 100 training points
  âœ“ Generated 200 evaluation points

[STEP 2] Fit RK4Solver to noisy training data...
  âœ“ Solver fitted successfully

[STEP 3] Fit RK45Solver to noisy training data...
  âœ“ Solver fitted successfully

[STEP 4] Evaluate metrics on fine evaluation grid...
  RK4Solver:
    RMSE: 0.0089
    RÂ²: 0.9989
  RK45Solver:
    RMSE: 0.0083
    RÂ²: 0.9991

[STEP 5] Plot results and save to disk...
  âœ“ Plot saved to examples/week1_demo.png
```

### When to Use

- âœ… Learning how solvers work
- âœ… Comparing different ODE methods
- âœ… Understanding SINDy system identification
- âœ… Evaluating solver accuracy metrics

---

## Week 2 Demo: `examples/week2_demo.py`

### What It Shows

1. **Generate synthetic ODE data** (3% noise, 150 points)
2. **Fit solver** (RK45 with SINDy)
3. **Compute residuals** (prediction errors)
4. **Run 4 statistical tests**:
   - Breusch-Pagan (heteroscedasticity)
   - Ljung-Box (autocorrelation)
   - ADF (stationarity)
   - State-Dependence
5. **Generate report** (test results + recommendations)
6. **Create visualizations** (2Ã—2 diagnostic plot)
7. **Interpret results** (what failures mean)
8. **Suggest improvements** (how to fix issues)

### Key Output

```
[STEP 1] Generate synthetic exponential decay data with noise
  â€¢ Time points: 150 (0 to 5 seconds)
  â€¢ Noise level: 3%
  âœ“ Synthetic data generated successfully

[STEP 2] Fit RK45Solver to noisy data using SINDy
  âœ“ Solver fitted successfully

[STEP 3] Generate predictions and compute residuals
  â€¢ Residuals mean: -0.0547
  â€¢ Residuals std: 0.068
  â€¢ RMSE: 0.0873

[STEP 4] Run comprehensive statistical diagnostic tests
  âœ“ All diagnostic tests completed successfully

  Test Results:
  - Breusch-Pagan Test (Heteroscedasticity)        FAILED âœ—
  - Ljung-Box Test (Autocorrelation)               FAILED âœ—
  - ADF Test (Stationarity)                        FAILED âœ—
  - State-Dependence Test                          FAILED âœ—

[STEP 5] Generate diagnostic report
  Detected Issues: heteroscedastic, autocorrelated, 
                   nonstationary, state_dependent
  
  Recommendation: Consider regime-switching model or 
                  time-varying parameters

[STEP 6] Create diagnostic visualizations
  âœ“ Diagnostic plot saved
  â€¢ Location: examples/week2_diagnostics.png
  â€¢ File size: 282 KB

[STEP 7] Formatted diagnostic summary table
  DIAGNOSTIC TEST RESULTS
  Test Name                    Detected  P-Value
  Breusch-Pagan              YES       0.000000  FAILED âœ—
  Ljung-Box                  YES       0.000000  FAILED âœ—
  ADF Test                   YES       0.998023  FAILED âœ—
  State-Dependence           YES       0.000000  FAILED âœ—

[STEP 8] Interpretation and next steps
  âš  Issues Detected (4 failures)
  
  â€¢ Heteroscedasticity detected â†’ Consider SDE formulation
  â€¢ Autocorrelation detected â†’ Add missing terms/complexity
  â€¢ Non-stationarity detected â†’ Check for regime changes
  â€¢ State-dependence detected â†’ Use adaptive error correction
```

### Diagnostic Plot (2Ã—2 Grid)

**Top-left: Residuals over time**
- Scatter plot with zero reference line
- Should be: Random around zero
- Warning: Systematic trends indicate bias

**Top-right: Autocorrelation (ACF)**
- Bar plot with confidence interval
- Should be: Bars within shaded region
- Warning: Bars outside suggest correlation

**Bottom-left: Q-Q plot**
- Normal probability plot
- Should be: Points near diagonal line
- Warning: Deviation indicates non-normality

**Bottom-right: Variance trend**
- Rolling standard deviation
- Should be: Flat horizontal line
- Warning: Trending indicates heteroscedasticity

### When to Use

- âœ… Validating solver quality
- âœ… Detecting systematic model errors
- âœ… Understanding residual structure
- âœ… Guiding solver improvements
- âœ… Learning diagnostic methods

---

## Complete Pipeline: Week 1 â†’ Week 2

```
Real-world ODE Problem
        â†“
[WEEK 1] Fit Solver with SINDy
        â†“
Generate Predictions
        â†“
Compute Residuals
        â†“
[WEEK 2] Run Diagnostics
        â†“
Statistical Tests (4 types)
        â†“
Identify Issues
        â†“
Get Recommendations
        â†“
Improve Solver / Method
        â†“
[Loop back or accept solution]
```

### Example Use Case: Building a Production ODE Solver

1. **Generate realistic test data** with noise
2. **Fit multiple solvers** (Week 1 capabilities)
3. **Compare performance** (metrics, speed)
4. **Select best solver** (e.g., RK45)
5. **Run diagnostics** (Week 2 framework)
6. **Identify issues** (e.g., autocorrelation, state-dependence)
7. **Improve solver** (e.g., add SDE formulation, Neural ODE)
8. **Re-run diagnostics** (validate improvement)
9. **Deploy to production** (confident in quality)

---

## File Locations

```
examples/
â”œâ”€â”€ week1_demo.py              â† Solver demonstration
â”œâ”€â”€ week1_demo.png             â† Generated solver plot
â”œâ”€â”€ week2_demo.py              â† Diagnostics demonstration
â”œâ”€â”€ week2_diagnostics.png      â† Generated diagnostic plot
â”œâ”€â”€ WEEK2_DEMO_README.md       â† Detailed diagnostics guide
â””â”€â”€ README.md                  â† Project overview

ode_framework/
â”œâ”€â”€ solvers/
â”‚   â””â”€â”€ classical.py           â† RK4Solver, RK45Solver
â”œâ”€â”€ diagnostics/
â”‚   â”œâ”€â”€ statistical_tests.py   â† 4 statistical tests
â”‚   â”œâ”€â”€ diagnostic_engine.py   â† Orchestration engine
â”‚   â””â”€â”€ visualizations.py      â† Plotting functions
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ test_problems.py       â† exponential_decay, etc.
â””â”€â”€ tests/
    â””â”€â”€ test_diagnostics.py    â† 65 comprehensive tests
```

---

## Common Tasks

### Task: Test a new solver

```bash
# 1. Run Week 1 demo to establish baseline
python examples/week1_demo.py

# 2. Create custom solver in ode_framework/solvers/
# 3. Update week1_demo.py to include your solver
# 4. Re-run to compare performance
```

### Task: Improve a solver that fails diagnostics

```bash
# 1. Run Week 2 demo to see what fails
python examples/week2_demo.py

# 2. Review the failure type:
#    - Autocorrelation â†’ Add complexity
#    - Heteroscedasticity â†’ Increase tolerance
#    - Non-stationarity â†’ Use regime model
#    - State-dependence â†’ Use adaptive method

# 3. Modify solver accordingly

# 4. Re-run to verify improvement
python examples/week2_demo.py
```

### Task: Create a custom diagnostic test

```python
# In ode_framework/diagnostics/statistical_tests.py
def my_custom_test(residuals, threshold=0.05):
    """My custom diagnostic test."""
    # Your test implementation
    return {"p_value": p_val, "my_metric": result}

# Add to DiagnosticEngine.run_diagnostics()
# Create test in ode_framework/tests/test_diagnostics.py
# Run: pytest ode_framework/tests/test_diagnostics.py -v
```

---

## Requirements

```bash
# Install all dependencies
pip install numpy scipy matplotlib statsmodels pysindy pytest

# Or install from requirements
pip install -r requirements.txt
```

### Optional for performance
```bash
pip install numba numexpr
```

---

## Troubleshooting

### Demo runs but produces no output
- Check that `matplotlib` backend is configured
- Verify `pandas` and `statsmodels` are installed
- Try: `python -c "import matplotlib; print(matplotlib.get_backend())"`

### Plots not saving
- Ensure `examples/` directory is writable
- Check disk space available
- Try running with admin/sudo if permission denied

### ImportError for pysindy
- Install: `pip install pysindy`
- Note: Requires Python 3.7+

### SINDy warnings during fit
- These are normal and expected
- Suppress with: `warnings.filterwarnings('ignore')`

### Slow execution
- Reduce number of time points
- Use RK4 instead of RK45 (faster, less accurate)
- Increase solver tolerance (less accurate, faster)

---

## Learning Path

### Beginner (Start Here)
1. Read this guide
2. Run `week1_demo.py`
3. Run `week2_demo.py`
4. Review generated plots
5. Read output interpretation guide

### Intermediate
1. Modify demo parameters (noise level, time span)
2. Try different test problems (logistic, harmonic)
3. Read WEEK2_DEMO_README.md in detail
4. Explore `ode_framework/diagnostics/` source
5. Review statistical test functions

### Advanced
1. Create custom solvers
2. Implement custom diagnostic tests
3. Modify demo to test your ideas
4. Read WEEK2_TESTING_SUMMARY.md (65 tests)
5. Contribute improvements to framework

---

## Key Insights

### From Week 1
- Multiple solvers have different trade-offs
- SINDy can learn ODEs from noisy data
- RK45 is generally better than RK4 (adaptive)
- Metrics matter: RMSE, RÂ², convergence

### From Week 2
- Residuals tell important stories
- Statistical tests are automated validators
- Different failures need different solutions
- Diagnostics guide model improvements
- Visual inspection complements statistics

---

## Quick Reference: Diagnostic Failures

| Test | Failure | Cause | Solution |
|------|---------|-------|----------|
| **Heteroscedasticity** | Variance changes | Model incomplete | SDE, adaptive |
| **Autocorrelation** | Residuals correlated | Missing structure | Add terms, Neural ODE |
| **Non-stationarity** | Mean/variance shift | Regime changes | Switching model, time-varying |
| **State-dependence** | Error depends on state | State-specific error | Adaptive error, local models |

---

## Next Steps

After running the demos:

1. **Review the test suite**: `pytest ode_framework/tests/test_diagnostics.py -v`
2. **Explore the source code**: `ode_framework/diagnostics/`
3. **Modify and experiment**: Edit demos to test ideas
4. **Create custom tests**: Implement your own diagnostics
5. **Build real applications**: Use framework for your problems

---

## Further Reading

- `WEEK2_TESTING_SUMMARY.md` - Comprehensive testing documentation
- `examples/WEEK2_DEMO_README.md` - Detailed diagnostics guide
- `ode_framework/diagnostics/README.md` - Module documentation (if available)
- Source code docstrings - Inline documentation in Python files

---

## Summary

The demo framework demonstrates:
- âœ… How to solve ODEs with multiple solvers (Week 1)
- âœ… How to validate solutions with diagnostics (Week 2)
- âœ… How to interpret diagnostic results
- âœ… How to guide solver improvements
- âœ… Complete pipeline from problem to production

**Start with:** `python examples/week2_demo.py`

**Learn more:** See `examples/WEEK2_DEMO_README.md`

**Test everything:** `pytest ode_framework/tests/ -v`

Happy exploring! ðŸš€
